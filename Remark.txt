Remark:
Date: Mar/5/2019
1. Initialized model prediect 87%(300) as class2(means error 1).
	Init the model parameter using standard normal distribution.

Meeting: Mar/7/2019
1. predicted anomaly error rollback
2. Init -> normal; (clustering methods)
3. Plot F1, ...
	Result. 1. result shows in result_back_predict_negative_error_300.eps
			   xls in incrementalAD/Experiments/compare_Mar_5.ods.
			   It will increase and drop times, then predict all to postive.
			2. not cluster, another easy way.
				result shown as result_back_predict_negative_newinit.eps
			3.

Meeting: Mar/19/2019
    0. notice the batch size.
    1. plot 2 class results
    2. chose class plot, not metrics plot.
    3. ROC curve.
    
    Result:
      0. result folder is the result of test_MCL21LS_compare_Back.m (not newinit, 100 batchsize)
      1. plot 2-class results
      	 whether only 2 classes or statistic 2 postive error negative error?
      	 
      	 two classes:
      	 still follow the negative rollback manner? same reason.
      	 if need to prone to normal? (as distribution is not extreme imbalance) 
      	 	N: /L1LS/test_L1LS_Back_negative.m Prone_normal=false;
      	 	The wave highly related to batch size, but the genreal trend is the same.
            Y: /L1LS/test_L1LS_Back_negative.m Prone_normal=true;
            The result is similar to N. 
            result and figure: excute /L1LS/test_L1LS_Back_negative.m
      	 postive error negative error:
      	    Don't know how to calculate TP,TN,FP,FN
      3. ROC is not for distance based algorithms, especially for possibility based algorithmsbut we can still use it as a generalization.[min:step:max]
      We save the ROC curve as gif, and show the AUC value in the code.

